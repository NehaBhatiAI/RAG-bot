{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d46f0e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.12.0-cp313-cp313-win_amd64.whl.metadata (5.2 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.3.2-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.56.0-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting tqdm (from sentence-transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Using cached torch-2.8.0-cp313-cp313-win_amd64.whl.metadata (30 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Using cached scikit_learn-1.7.1-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.16.1-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting Pillow (from sentence-transformers)\n",
      "  Using cached pillow-11.3.0-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting typing_extensions>=4.5.0 (from sentence-transformers)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\nehab\\onedrive\\desktop\\p4 (rag-bot)\\env\\lib\\site-packages (from faiss-cpu) (25.0)\n",
      "Collecting charset_normalizer<4,>=2 (from requests)\n",
      "  Using cached charset_normalizer-3.4.3-cp313-cp313-win_amd64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pyyaml>=5.1 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Using cached PyYAML-6.0.2-cp313-cp313-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting setuptools (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\nehab\\onedrive\\desktop\\p4 (rag-bot)\\env\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading regex-2025.9.1-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.22.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl.metadata (4.1 kB)\n",
      "Using cached sentence_transformers-5.1.0-py3-none-any.whl (483 kB)\n",
      "Downloading faiss_cpu-1.12.0-cp313-cp313-win_amd64.whl (18.2 MB)\n",
      "   ---------------------------------------- 0.0/18.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/18.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/18.2 MB 2.2 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.6/18.2 MB 2.9 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 2.1/18.2 MB 2.7 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 2.4/18.2 MB 2.6 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 2.6/18.2 MB 2.4 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 2.9/18.2 MB 2.3 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 3.4/18.2 MB 2.1 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 3.7/18.2 MB 2.0 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 4.2/18.2 MB 2.0 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 4.7/18.2 MB 2.1 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 5.2/18.2 MB 2.1 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 6.0/18.2 MB 2.2 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 6.8/18.2 MB 2.4 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 8.1/18.2 MB 2.6 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 9.2/18.2 MB 2.8 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 10.5/18.2 MB 3.0 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 12.1/18.2 MB 3.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 13.4/18.2 MB 3.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 14.7/18.2 MB 3.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 16.3/18.2 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 16.8/18.2 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.2/18.2 MB 3.8 MB/s eta 0:00:00\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached numpy-2.3.2-cp313-cp313-win_amd64.whl (12.8 MB)\n",
      "Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Using cached charset_normalizer-3.4.3-cp313-cp313-win_amd64.whl (107 kB)\n",
      "Using cached huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached torch-2.8.0-cp313-cp313-win_amd64.whl (241.3 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading transformers-4.56.0-py3-none-any.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/11.6 MB 5.9 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.8/11.6 MB 4.6 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.9/11.6 MB 4.3 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.4/11.6 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.2/11.6 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.7/11.6 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.2/11.6 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.8/11.6 MB 3.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.3/11.6 MB 3.3 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.8/11.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.3/11.6 MB 3.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 7.6/11.6 MB 3.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.1/11.6 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 8.9/11.6 MB 2.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.7/11.6 MB 3.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.2/11.6 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.7/11.6 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.3/11.6 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 2.9 MB/s eta 0:00:00\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached pillow-11.3.0-cp313-cp313-win_amd64.whl (7.0 MB)\n",
      "Using cached scikit_learn-1.7.1-cp313-cp313-win_amd64.whl (8.7 MB)\n",
      "Using cached scipy-1.16.1-cp313-cp313-win_amd64.whl (38.5 MB)\n",
      "Using cached fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached PyYAML-6.0.2-cp313-cp313-win_amd64.whl (156 kB)\n",
      "Downloading regex-2025.9.1-cp313-cp313-win_amd64.whl (275 kB)\n",
      "Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.22.0-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/2.7 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.3/2.7 MB 3.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.8/2.7 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.7 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 3.1 MB/s eta 0:00:00\n",
      "Using cached filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl (15 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, urllib3, typing_extensions, tqdm, threadpoolctl, sympy, setuptools, safetensors, regex, pyyaml, python-dotenv, Pillow, numpy, networkx, MarkupSafe, joblib, idna, fsspec, filelock, charset_normalizer, certifi, scipy, requests, jinja2, faiss-cpu, torch, scikit-learn, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "Successfully installed MarkupSafe-3.0.2 Pillow-11.3.0 certifi-2025.8.3 charset_normalizer-3.4.3 faiss-cpu-1.12.0 filelock-3.19.1 fsspec-2025.7.0 huggingface-hub-0.34.4 idna-3.10 jinja2-3.1.6 joblib-1.5.2 mpmath-1.3.0 networkx-3.5 numpy-2.3.2 python-dotenv-1.1.1 pyyaml-6.0.2 regex-2025.9.1 requests-2.32.5 safetensors-0.6.2 scikit-learn-1.7.1 scipy-1.16.1 sentence-transformers-5.1.0 setuptools-80.9.0 sympy-1.14.0 threadpoolctl-3.6.0 tokenizers-0.22.0 torch-2.8.0 tqdm-4.67.1 transformers-4.56.0 typing_extensions-4.15.0 urllib3-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers faiss-cpu requests python-dotenv numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "145f1736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nehab\\OneDrive\\Desktop\\P4 (RAG-bot)\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56bacbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm_model = \"llama-3.3-70b-versatile\"\n",
    "API_URL = \"https://api.groq.com/openai/v1/chat/completions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca7af59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Step 3: Load the Embedding Model \"\"\"\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embedding_dim = embedding_model.get_sentence_embedding_dimension()  # Typically 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c541d7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Step 4: Prepare Your Documents \"\"\"\n",
    "documents = [\n",
    "    \"The capital of France is Paris.\",\n",
    "    \"Python is a popular programming language.\",\n",
    "    \"Machine learning is a subset of artificial intelligence.\",\n",
    "    \"The Eiffel Tower is in Paris.\",\n",
    "    \"Groq provides fast AI inference.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bdfd75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Step 5: Generate Embeddings for Documents \"\"\"\n",
    "doc_embeddings = embedding_model.encode(documents)\n",
    "doc_embeddings = np.array(doc_embeddings).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fff45003",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Step 6: Set Up FAISS Vector Database \"\"\"\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "index.add(doc_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56205952",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Step 7: Define Retrieval and Response Functions \"\"\"\n",
    "\n",
    "def retrieve_documents(query, top_k=3):\n",
    "    query_embedding = embedding_model.encode([query])\n",
    "    query_embedding = np.array(query_embedding).astype('float32')\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "    retrieved_docs = [documents[i] for i in indices[0]]\n",
    "    return retrieved_docs\n",
    "\n",
    "def generate_response(query, retrieved_docs, temperature=0.4):\n",
    "    context = \"\\n\".join([f\"- {doc}\" for doc in retrieved_docs])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a concise and accurate assistant. Use the provided context to answer the query directly and clearly. \n",
    "    If the context doesn't contain relevant information, then simply say: **Can't provide a valid ans**.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Query: {query}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {GROQ_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": llm_model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": temperature\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(API_URL, headers=headers, data=json.dumps(data))\n",
    "        if response.status_code == 200:\n",
    "            response_data = response.json()\n",
    "            return response_data['choices'][0]['message']['content'].strip()\n",
    "        else:\n",
    "            return f\"Error {response.status_code}: {response.text}\"\n",
    "    except requests.RequestException as e:\n",
    "        return f\"API request failed: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bea62c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Documents: ['Python is a popular programming language.', 'Machine learning is a subset of artificial intelligence.']\n",
      "Generated Response: **Can't provide a valid answer**\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Example Usage \"\"\"\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"What is Django?\"\n",
    "    retrieved = retrieve_documents(query, top_k=2)\n",
    "    print(\"Retrieved Documents:\", retrieved)\n",
    "\n",
    "    response = generate_response(query, retrieved)\n",
    "    print(\"Generated Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e3c075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
